{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4d8256",
   "metadata": {},
   "source": [
    "# Project 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8a627f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486953e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf537a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def franke(x,y):\n",
    "    return 3/4 * np.exp(- (9*x - 2)**2 /4 - (9*y -2)**2 /4) + 3/4 * np.exp(- (9*x + 1)**2 /49 - (9*y +1) /10) + 1/2* np.exp(- (9*x -7)**2 / 4 - (9*y - 3)**2 /4) - 1/5* np.exp(- (9*x -4)**2 - (9*y - 7)**2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb84542",
   "metadata": {},
   "source": [
    "## Making datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ec19e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(10000,2)\n",
    "y = franke(X[:,0], X[:,1])\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345ce2a",
   "metadata": {},
   "source": [
    "## OLS with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15bbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "def f(x, y, b):\n",
    "    return (b[0] + b[1]*x[:,0] + b[2]*x[:,1] - y)\n",
    "\n",
    "def res(x, y, b):\n",
    "    return sum(f(x,y, b)*f(x, y, b))\n",
    "\n",
    "def grad(x, y, b):\n",
    "    return np.array([\n",
    "            sum(f(x, y, b)),\n",
    "            sum(x[:,0]*f(x, y, b)),\n",
    "            sum(x[:,1]*f(x, y, b))\n",
    "    ])\n",
    "\n",
    "def gd(b_start, gradient, max_iter, learning_rate):\n",
    "    b = np.array(b_start, dtype='float64')\n",
    "    print(b)\n",
    "    for i in range(max_iter):\n",
    "        grad = gradient(X_train, y_train, b)\n",
    "        b -= grad * learning_rate\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Iter {i}: resiudal {res(X_train, y_train, b)}\") \n",
    "        if abs(sum(grad)) < 1e-7:\n",
    "            break;\n",
    "    print(f\"Iter {i}: resiudal {res(X_train, y_train, b)}\")\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8f1e8f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "Iter 0: resiudal 1530.2153312433531\n",
      "Iter 200: resiudal 293.03927695836103\n",
      "Iter 400: resiudal 190.6476720530112\n",
      "Iter 600: resiudal 168.12393232301883\n",
      "Iter 800: resiudal 163.16035820940346\n",
      "Iter 1000: resiudal 162.06571652526566\n",
      "Iter 1200: resiudal 161.82423510702927\n",
      "Iter 1400: resiudal 161.7709567107779\n",
      "Iter 1600: resiudal 161.7592011957475\n",
      "Iter 1800: resiudal 161.75660736429225\n",
      "Iter 2000: resiudal 161.7560350352135\n",
      "Iter 2200: resiudal 161.75590875028482\n",
      "Iter 2400: resiudal 161.7558808853577\n",
      "Iter 2600: resiudal 161.75587473692346\n",
      "Iter 2800: resiudal 161.7558733802624\n",
      "Iter 3000: resiudal 161.75587308091357\n",
      "Iter 3200: resiudal 161.75587301486075\n",
      "Iter 3400: resiudal 161.75587300028687\n",
      "Iter 3600: resiudal 161.75587299707092\n",
      "Iter 3800: resiudal 161.75587299636135\n",
      "Iter 4000: resiudal 161.75587299620466\n",
      "Iter 4200: resiudal 161.75587299616998\n",
      "Iter 4400: resiudal 161.7558729961631\n",
      "Iter 4600: resiudal 161.75587299616035\n",
      "Iter 4800: resiudal 161.75587299616103\n",
      "Iter 5000: resiudal 161.75587299615958\n",
      "Iter 5200: resiudal 161.75587299616\n",
      "Iter 5400: resiudal 161.75587299616055\n",
      "Iter 5600: resiudal 161.75587299616026\n",
      "Iter 5735: resiudal 161.75587299616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99004635, -0.50949427, -0.66669848])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_start = [0,0,0]\n",
    "max_iter = 10000\n",
    "learning_rate = 0.00001\n",
    "bstar = gd(b_start, grad, max_iter, learning_rate)\n",
    "bstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04851983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.31630415327603273\n",
      "MSE using ols on test : 0.3131597526632503\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(f(X_train,y_train,bstar)-y_train, 2))\n",
    "mse_test = np.mean(np.power(f(X_test,y_test,bstar)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bf145",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ca7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "Iter 0: resiudal 1530.2153312433531\n",
      "Iter 200: resiudal 293.09186305187336\n",
      "Iter 400: resiudal 190.7101076093674\n",
      "Iter 600: resiudal 168.1673631438506\n",
      "Iter 800: resiudal 163.18519454318795\n",
      "Iter 1000: resiudal 162.0787061386296\n",
      "Iter 1200: resiudal 161.8307582073965\n",
      "Iter 1400: resiudal 161.77419635715557\n",
      "Iter 1600: resiudal 161.7608340900215\n",
      "Iter 1800: resiudal 161.75746916242562\n",
      "Iter 2000: resiudal 161.7565305879002\n",
      "Iter 2200: resiudal 161.7562313005965\n",
      "Iter 2400: resiudal 161.75612195083528\n",
      "Iter 2600: resiudal 161.75607748055944\n",
      "Iter 2800: resiudal 161.75605811542147\n",
      "Iter 3000: resiudal 161.75604935678794\n",
      "Iter 3200: resiudal 161.75604531788898\n",
      "Iter 3400: resiudal 161.7560434376852\n",
      "Iter 3600: resiudal 161.75604255842427\n",
      "Iter 3800: resiudal 161.75604214636\n",
      "Iter 4000: resiudal 161.75604195305178\n",
      "Iter 4200: resiudal 161.75604186232187\n",
      "Iter 4400: resiudal 161.7560418197288\n",
      "Iter 4600: resiudal 161.7560417997313\n",
      "Iter 4800: resiudal 161.7560417903419\n",
      "Iter 5000: resiudal 161.75604178593395\n",
      "Iter 5200: resiudal 161.75604178386226\n",
      "Iter 5400: resiudal 161.75604178289072\n",
      "Iter 5600: resiudal 161.7560417824345\n",
      "Iter 5732: resiudal 161.75604178227627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.98964508, -0.50914448, -0.66629516])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 0.1\n",
    "\n",
    "def grad_ridge(x, y, b):\n",
    "    return np.array([\n",
    "            sum(f(x, y, b)) + 2*l*b[0],\n",
    "            sum(x[:,0]*f(x, y, b)) + 2*l*b[1],\n",
    "            sum(x[:,1]*f(x, y, b)) + 2*l*b[2]\n",
    "    ])\n",
    "\n",
    "b_start = [0,0,0]\n",
    "max_iter = 10000\n",
    "learning_rate = 0.00001\n",
    "bstar = gd(b_start, grad_ridge, max_iter, learning_rate)\n",
    "bstar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2d6ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.31640037260886505\n",
      "MSE using ols on test : 0.3132511193718508\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(f(X_train,y_train,bstar)-y_train, 2))\n",
    "mse_test = np.mean(np.power(f(X_test,y_test,bstar)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237b5ce9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "Iter 0: resiudal 1530.2153312433531\n",
      "Iter 200: resiudal 293.5650553711091\n",
      "Iter 400: resiudal 191.27379621651878\n",
      "Iter 600: resiudal 168.5636623001126\n",
      "Iter 800: resiudal 163.41765698455168\n",
      "Iter 1000: resiudal 162.2070865527713\n",
      "Iter 1200: resiudal 161.90252702113298\n",
      "Iter 1400: resiudal 161.8173288832136\n",
      "Iter 1600: resiudal 161.79000819799214\n",
      "Iter 1800: resiudal 161.77997101720607\n",
      "Iter 2000: resiudal 161.77587598838855\n",
      "Iter 2200: resiudal 161.774091671334\n",
      "Iter 2400: resiudal 161.7732856768663\n",
      "Iter 2600: resiudal 161.77291489709083\n",
      "Iter 2800: resiudal 161.77274280792713\n",
      "Iter 3000: resiudal 161.77266259804264\n",
      "Iter 3200: resiudal 161.77262513788915\n",
      "Iter 3400: resiudal 161.77260762656866\n",
      "Iter 3600: resiudal 161.77259943702802\n",
      "Iter 3800: resiudal 161.77259560622358\n",
      "Iter 4000: resiudal 161.77259381412367\n",
      "Iter 4200: resiudal 161.77259297571717\n",
      "Iter 4400: resiudal 161.77259258347294\n",
      "Iter 4600: resiudal 161.77259239996215\n",
      "Iter 4800: resiudal 161.7725923141071\n",
      "Iter 5000: resiudal 161.77259227393927\n",
      "Iter 5200: resiudal 161.77259225514584\n",
      "Iter 5400: resiudal 161.77259224635415\n",
      "Iter 5600: resiudal 161.772592242241\n",
      "Iter 5705: resiudal 161.77259224105148\n",
      "MSE using ols on train : 0.31726417559474834\n",
      "MSE using ols on test : 0.3140714756225774\n"
     ]
    }
   ],
   "source": [
    "l = 1\n",
    "bstar = gd(b_start, grad_ridge, max_iter, learning_rate)\n",
    "mse_train = np.mean(np.power(f(X_train,y_train,bstar)-y_train, 2))\n",
    "mse_test = np.mean(np.power(f(X_test,y_test,bstar)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff2c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "Iter 0: resiudal 1530.2153312433531\n",
      "Iter 200: resiudal 298.28819818248417\n",
      "Iter 400: resiudal 197.07463763426406\n",
      "Iter 600: resiudal 173.02660903907608\n",
      "Iter 800: resiudal 166.5590337421261\n",
      "Iter 1000: resiudal 164.53187306057796\n",
      "Iter 1200: resiudal 163.7985692859224\n",
      "Iter 1400: resiudal 163.5046314701731\n",
      "Iter 1600: resiudal 163.3795268527513\n",
      "Iter 1800: resiudal 163.32461020598075\n",
      "Iter 2000: resiudal 163.3001427907184\n",
      "Iter 2200: resiudal 163.2891659968972\n",
      "Iter 2400: resiudal 163.2842258549635\n",
      "Iter 2600: resiudal 163.28199931663784\n",
      "Iter 2800: resiudal 163.28099515004692\n",
      "Iter 3000: resiudal 163.2805421368737\n",
      "Iter 3200: resiudal 163.2803377397175\n",
      "Iter 3400: resiudal 163.28024551107865\n",
      "Iter 3600: resiudal 163.28020389423844\n",
      "Iter 3800: resiudal 163.28018511499326\n",
      "Iter 4000: resiudal 163.2801766409674\n",
      "Iter 4200: resiudal 163.2801728171001\n",
      "Iter 4400: resiudal 163.28017109159467\n",
      "Iter 4600: resiudal 163.28017031296696\n",
      "Iter 4800: resiudal 163.28016996161313\n",
      "Iter 5000: resiudal 163.28016980306725\n",
      "Iter 5200: resiudal 163.28016973152188\n",
      "Iter 5400: resiudal 163.28016969923883\n",
      "Iter 5446: resiudal 163.28016969479927\n",
      "MSE using ols on train : 0.3256877455082978\n",
      "MSE using ols on test : 0.32208190886987625\n"
     ]
    }
   ],
   "source": [
    "l = 10\n",
    "bstar = gd(b_start, grad_ridge, max_iter, learning_rate)\n",
    "mse_train = np.mean(np.power(f(X_train,y_train,bstar)-y_train, 2))\n",
    "mse_test = np.mean(np.power(f(X_test,y_test,bstar)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d88364",
   "metadata": {},
   "source": [
    "## ANN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10b317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer():\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.normal(size = (input_size, output_size))\n",
    "        self.bias = np.random.normal(size = (1, output_size))\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dA_l. Returns input_error=dE/dAl-1.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error\n",
    "\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15eebd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer():\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8672b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2;\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.greater(x, 0).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "125395ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and its derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da3208bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "        \n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f414e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15   error=0.168115\n",
      "epoch 2/15   error=0.007644\n",
      "epoch 3/15   error=0.006889\n",
      "epoch 4/15   error=0.006695\n",
      "epoch 5/15   error=0.006593\n",
      "epoch 6/15   error=0.006514\n",
      "epoch 7/15   error=0.006446\n",
      "epoch 8/15   error=0.006385\n",
      "epoch 9/15   error=0.006329\n",
      "epoch 10/15   error=0.006277\n",
      "epoch 11/15   error=0.006228\n",
      "epoch 12/15   error=0.006181\n",
      "epoch 13/15   error=0.006137\n",
      "epoch 14/15   error=0.006096\n",
      "epoch 15/15   error=0.006056\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(10000, 1, 2)\n",
    "y = y.reshape(10000, 1 ,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 20))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(20, 10))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs= 15, learning_rate=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12b24bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.006124849349267002\n",
      "MSE using ols on test : 0.00596695522880237\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(net.predict(X_train)-y_train, 2))\n",
    "mse_test = np.mean(np.power(net.predict(X_test)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a101c594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15   error=0.085031\n",
      "epoch 2/15   error=0.010259\n",
      "epoch 3/15   error=0.008299\n",
      "epoch 4/15   error=0.006928\n",
      "epoch 5/15   error=0.005408\n",
      "epoch 6/15   error=0.004409\n",
      "epoch 7/15   error=0.003998\n",
      "epoch 8/15   error=0.003786\n",
      "epoch 9/15   error=0.003652\n",
      "epoch 10/15   error=0.003544\n",
      "epoch 11/15   error=0.003445\n",
      "epoch 12/15   error=0.003367\n",
      "epoch 13/15   error=0.003287\n",
      "epoch 14/15   error=0.003227\n",
      "epoch 15/15   error=0.003179\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 20))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(20, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=15, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69a35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.0028292818309489077\n",
      "MSE using ols on test : 0.00273919293654\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(net.predict(X_train)-y_train, 2))\n",
    "mse_test = np.mean(np.power(net.predict(X_test)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf059abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15   error=0.035261\n",
      "epoch 2/15   error=0.021940\n",
      "epoch 3/15   error=0.020446\n",
      "epoch 4/15   error=0.019693\n",
      "epoch 5/15   error=0.019219\n",
      "epoch 6/15   error=0.018893\n",
      "epoch 7/15   error=0.018654\n",
      "epoch 8/15   error=0.018472\n",
      "epoch 9/15   error=0.018326\n",
      "epoch 10/15   error=0.018207\n",
      "epoch 11/15   error=0.018104\n",
      "epoch 12/15   error=0.018013\n",
      "epoch 13/15   error=0.017931\n",
      "epoch 14/15   error=0.017854\n",
      "epoch 15/15   error=0.017780\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 20))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "net.add(FCLayer(20, 10))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=15, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7847837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.0187771308907652\n",
      "MSE using ols on test : 0.018516315885335297\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(net.predict(X_train)-y_train, 2))\n",
    "mse_test = np.mean(np.power(net.predict(X_test)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062bb997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15   error=0.041375\n",
      "epoch 2/15   error=0.018077\n",
      "epoch 3/15   error=0.010534\n",
      "epoch 4/15   error=0.007362\n",
      "epoch 5/15   error=0.006011\n",
      "epoch 6/15   error=0.005206\n",
      "epoch 7/15   error=0.004650\n",
      "epoch 8/15   error=0.004248\n",
      "epoch 9/15   error=0.004004\n",
      "epoch 10/15   error=0.003876\n",
      "epoch 11/15   error=0.003780\n",
      "epoch 12/15   error=0.003700\n",
      "epoch 13/15   error=0.003628\n",
      "epoch 14/15   error=0.003564\n",
      "epoch 15/15   error=0.003503\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 20))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(20, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(X_train, y_train, epochs=15, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6755fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using ols on train : 0.003428019180475225\n",
      "MSE using ols on test : 0.0032911804437067474\n"
     ]
    }
   ],
   "source": [
    "mse_train = np.mean(np.power(net.predict(X_train)-y_train, 2))\n",
    "mse_test = np.mean(np.power(net.predict(X_test)-y_test, 2))\n",
    "print(f\"MSE using ols on train : {mse_train}\")\n",
    "print(f\"MSE using ols on test : {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1c97c",
   "metadata": {},
   "source": [
    "## Using tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82d4755c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "219/219 [==============================] - 0s 619us/step - loss: 0.0870\n",
      "Epoch 2/15\n",
      "219/219 [==============================] - 0s 610us/step - loss: 0.0456\n",
      "Epoch 3/15\n",
      "219/219 [==============================] - 0s 619us/step - loss: 0.0322\n",
      "Epoch 4/15\n",
      "219/219 [==============================] - 0s 612us/step - loss: 0.0270\n",
      "Epoch 5/15\n",
      "219/219 [==============================] - 0s 619us/step - loss: 0.0247\n",
      "Epoch 6/15\n",
      "219/219 [==============================] - 0s 615us/step - loss: 0.0234\n",
      "Epoch 7/15\n",
      "219/219 [==============================] - 0s 616us/step - loss: 0.0227\n",
      "Epoch 8/15\n",
      "219/219 [==============================] - 0s 619us/step - loss: 0.0222\n",
      "Epoch 9/15\n",
      "219/219 [==============================] - 0s 610us/step - loss: 0.0218\n",
      "Epoch 10/15\n",
      "219/219 [==============================] - 0s 615us/step - loss: 0.0215\n",
      "Epoch 11/15\n",
      "219/219 [==============================] - 0s 615us/step - loss: 0.0212\n",
      "Epoch 12/15\n",
      "219/219 [==============================] - 0s 619us/step - loss: 0.0210\n",
      "Epoch 13/15\n",
      "219/219 [==============================] - 0s 620us/step - loss: 0.0207\n",
      "Epoch 14/15\n",
      "219/219 [==============================] - 0s 615us/step - loss: 0.0205\n",
      "Epoch 15/15\n",
      "219/219 [==============================] - 0s 625us/step - loss: 0.0203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cae585b20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(20, activation = 'relu'),\n",
    "        layers.Dense(10, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'tanh'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.MeanSquaredError(),\n",
    "    optimizer = keras.optimizers.SGD()\n",
    ")\n",
    "\n",
    "model.fit(X_train.reshape(-1,2),y_train.reshape(-1,1), epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da23e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 559us/step - loss: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02001296915113926"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test.reshape(-1,2), y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc20ec",
   "metadata": {},
   "source": [
    "## Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa0e215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "df[\"target\"] = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bba8cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 1, 30) (569, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['target']).reshape(-1,1,1)\n",
    "x = np.array(df.drop('target', axis = 1)).reshape(-1,1,30)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "33a74f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025850929940455"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss function and its derivative\n",
    "def negative_log_loss(y_true, y_pred):\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true)*np.log(1- y_pred))\n",
    "\n",
    "def negative_log_loss_prime(y_true, y_pred):\n",
    "    return -(y_true + y_pred)/(y_pred*(1- y_pred)*y_true.size);\n",
    "\n",
    "negative_log_loss(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d987841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def linear_prime(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "be90af25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30   error=1.548828\n",
      "epoch 2/30   error=1.076472\n",
      "epoch 3/30   error=0.809425\n",
      "epoch 4/30   error=0.786945\n",
      "epoch 5/30   error=0.763921\n",
      "epoch 6/30   error=0.742671\n",
      "epoch 7/30   error=0.722429\n",
      "epoch 8/30   error=0.702515\n",
      "epoch 9/30   error=0.688431\n",
      "epoch 10/30   error=0.675819\n",
      "epoch 11/30   error=0.662931\n",
      "epoch 12/30   error=0.649694\n",
      "epoch 13/30   error=0.635807\n",
      "epoch 14/30   error=0.623137\n",
      "epoch 15/30   error=0.611828\n",
      "epoch 16/30   error=0.601393\n",
      "epoch 17/30   error=0.586184\n",
      "epoch 18/30   error=0.574554\n",
      "epoch 19/30   error=0.564809\n",
      "epoch 20/30   error=0.555285\n",
      "epoch 21/30   error=0.546716\n",
      "epoch 22/30   error=0.537940\n",
      "epoch 23/30   error=0.529294\n",
      "epoch 24/30   error=0.520908\n",
      "epoch 25/30   error=0.513514\n",
      "epoch 26/30   error=0.507127\n",
      "epoch 27/30   error=0.499807\n",
      "epoch 28/30   error=0.493315\n",
      "epoch 29/30   error=0.487842\n",
      "epoch 30/30   error=0.483415\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "net = Network()\n",
    "net.add(FCLayer(30, 30))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(30, 20))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "net.add(FCLayer(20, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "\n",
    "# train\n",
    "net.use(negative_log_loss, negative_log_loss_prime)\n",
    "net.fit(x, y, epochs= 30, learning_rate=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c22e466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8892794376098418\n"
     ]
    }
   ],
   "source": [
    "y_predict = net.predict(x)\n",
    "y_predict_label = np.zeros((y.shape[0],1))\n",
    "i = 0\n",
    "for prediction in y_predict:\n",
    "    if prediction[0] >= 0.5:\n",
    "        y_predict_label[i] = 1\n",
    "    else:\n",
    "        y_predict_label[i] = 0\n",
    "    i = i+1\n",
    "\n",
    "y_true = y[:,0]\n",
    "\n",
    "correct_classified = 0\n",
    "for i in range(len(y_predict_label)):\n",
    "    if y_predict_label[i] == y_true[i]:\n",
    "        correct_classified += 1\n",
    "        \n",
    "print(f\"Accuracy: {correct_classified/y_true.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f273321a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e32fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(-1,30)\n",
    "y = y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc1a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightInitialization(n_features):\n",
    "    w = np.zeros((1, n_features))\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "def sigmoid_activation(x):\n",
    "    return  1/(1+np.exp(-x))\n",
    "\n",
    "def logistic_regr_fit(w,b,X,Y, learning_rate,n_iter = 1000):\n",
    "    for i in range(n_iter):\n",
    "        m = X.shape[0]\n",
    "    \n",
    "        #Prediction\n",
    "        a = sigmoid_activation(np.dot(w,X.T)+b)\n",
    "        Y_T = Y.T\n",
    "        cost = (-1/m)*(np.sum((Y_T*np.log(a)) + ((1-Y_T)*(np.log(1-a)))))\n",
    "      \n",
    "    \n",
    "        #Gradient calculation\n",
    "        dw = (1/m)*(np.dot(X.T, (a-Y.T).T))\n",
    "        db = (1/m)*(np.sum(a-Y.T))\n",
    "    \n",
    "        #weight update\n",
    "        w = w - (learning_rate * (dw.T))\n",
    "        b = b - (learning_rate * db)\n",
    "        #\n",
    "        \n",
    "        if (i % 100 == 0):\n",
    "            print(\"Iter %i: Negative Log loss is %f\" %(i, cost))\n",
    "        \n",
    "    return w, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "498a45d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Negative Log loss is 0.693147\n",
      "Iter 100: Negative Log loss is 0.515389\n",
      "Iter 200: Negative Log loss is 0.448926\n",
      "Iter 300: Negative Log loss is 0.409006\n",
      "Iter 400: Negative Log loss is 0.381209\n",
      "Iter 500: Negative Log loss is 0.360256\n",
      "Iter 600: Negative Log loss is 0.343685\n",
      "Iter 700: Negative Log loss is 0.330165\n",
      "Iter 800: Negative Log loss is 0.318896\n",
      "Iter 900: Negative Log loss is 0.309358\n"
     ]
    }
   ],
   "source": [
    "w,b = weightInitialization(x.shape[1])\n",
    "w,b = logistic_regr_fit(w,b,x,y, 0.000005, n_iter = 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65baac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9121265377855887\n"
     ]
    }
   ],
   "source": [
    "y_predict = sigmoid_activation(np.dot(w,x.T)+b).T\n",
    "y_predict_label = np.zeros((y.shape[0],1))\n",
    "i = 0\n",
    "for prediction in y_predict:\n",
    "    if prediction >= 0.5:\n",
    "        y_predict_label[i] = 1\n",
    "    else:\n",
    "        y_predict_label[i] = 0\n",
    "    i = i+1\n",
    "\n",
    "y_true = y[:,0]\n",
    "\n",
    "correct_classified = 0\n",
    "for i in range(len(y_predict_label)):\n",
    "    if y_predict_label[i] == y_true[i]:\n",
    "        correct_classified += 1\n",
    "        \n",
    "print(f\"Accuracy: {correct_classified/y_true.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b7530",
   "metadata": {},
   "source": [
    "## Using tensorflow/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3efb23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 0s 882us/step - loss: 14.2444 - accuracy: 0.6063\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.8706 - accuracy: 0.8366\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5422 - accuracy: 0.8594\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.5246 - accuracy: 0.8752\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4561 - accuracy: 0.8928\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4558 - accuracy: 0.8787\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4253 - accuracy: 0.8858\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4885 - accuracy: 0.8752\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4301 - accuracy: 0.8946\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4079 - accuracy: 0.8963\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4110 - accuracy: 0.8893\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4488 - accuracy: 0.8893\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3711 - accuracy: 0.8963\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4229 - accuracy: 0.8822\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3537 - accuracy: 0.9033\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3991 - accuracy: 0.8963\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.3915 - accuracy: 0.9139\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3731 - accuracy: 0.9069\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.3537 - accuracy: 0.9121\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3585 - accuracy: 0.9069\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3968 - accuracy: 0.8998\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3814 - accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.3822 - accuracy: 0.8946\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.3762 - accuracy: 0.9121\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3656 - accuracy: 0.8910\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3111 - accuracy: 0.9209\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3712 - accuracy: 0.9104\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.3694 - accuracy: 0.9051\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3483 - accuracy: 0.9104\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.3474 - accuracy: 0.9016\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.5851 - accuracy: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5851401686668396, 0.8892794251441956]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(30, activation = 'relu'),\n",
    "        layers.Dense(20, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.00005),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x,y, epochs = 30)\n",
    "model.evaluate(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
